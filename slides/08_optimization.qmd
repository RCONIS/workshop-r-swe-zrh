---
title: "8 Code Optimization"
date: "2024-03-20"
description: "Best Practices for Optimizing Code<br/>[TODO]{.copyright}"
image: TODO
bibliography: references.bib
---

## Acknowledgments

This section is adapted from material by Michael Mayer and Lukas A. Widmer, which they prepared and released under the CC BY 4.0 license, see their course [Go fastR – how to make R code fast(er) and run it on high performance compute (HPC) clusters](https://luwidmer.github.io/fastR-website/materials.html).

Thanks a lot Michael and Lukas!

# Introduction

## A Word of Wisdom

![](screenshots/2024-03-17-22-24-36.png)

[@knuth1974structured, p. 268]

## Setting the right priorities

1. The code needs to be correct, i.e. calculate correct results as expected. → **Tests**, **Debugging**
1. If it is correct, but too slow, then find out which calculations and why they are too slow. → **Profiling**
1. Once you identified the slow parts, optimize those. 
→ **Code optimization**
1. If executing the code on your laptop is still too slow → consider running it instead on a high performance cluster (**HPC**), see slides from Michael and Lukas

## Tests: see previous chapter!

![](resources/testing.png)

(modified from @xkcd, [No. 303](https://xkcd.com/303/))

## Debugging: A few pointers

1. Post-hoc `traceback()` after code fails, to show the call stack and see how the error came about.
1. Setting `debug(myfun)` for the problematic function `myfun` and then run the code to step through its execution.
1. Inject `browser()` calls into problematic code to add "breakpoints" for interactive execution and inspection.
1. Setting `options(error = recover)` and then running the problematic code allows you to jump into the call stack and inspect. (Undo with `options(error = NULL)`)

# Profiling

## Profiling: Definition

> In software engineering, profiling ("program profiling", "software profiling") is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls. Most commonly, profiling information serves to aid program optimization, and more specifically, performance engineering.

([Wikipedia](https://en.wikipedia.org/wiki/Profiling_(computer_programming)))

## Profiling: Example code

```{r}
#| echo: TRUE
f <- function() {
    profvis::pause(0.1)
    for (i in seq_len(3)) {
        g()
    }
}
g <- function() {
    profvis::pause(0.1)
}
```

## Profiling: Let's identify the bottlenecks!

In R there are a couple of basic functions for profiling:

- `system.time()`
- `Rprof`: 
  1. start with `Rprof()`
  1. execute the code
  1. stop with `Rprof(NULL)`
  1. summarize with `summaryRprof()`

See e.g. @peng2016, chapter 19, for details.

## Profiling: Classic `Rprof` output

```{r}
#| echo: TRUE
Rprof()
f()
Rprof(NULL)
summaryRprof()
```

## Profiling: Getting visual

We can use the more modern [`profvis`](https://rstudio.github.io/profvis) R package for visualizing where R spends its time during code execution.

```{r}
#| eval: FALSE
#| echo: TRUE
library(profvis)
source("profexample.R") # Such that the flame graph includes code lines.
prof <- profvis({
    f()
})
print(prof)
```

## Profiling: `profvis` output

![](screenshots/2024-03-24-21-51-38.png)

# Code optimization

## Code optimization: Explore alternatives

- If the slow function is from another package, search for a faster one
- Runtime complexity (runtime as a function of data size) of different algorithms can be
wildly different - some work well on small data but take forever on large data
- Few examples:
  - For wrangling data frames, consider [`duckplyr`](https://duckdblabs.github.io/duckplyr/) and [`polars`](https://rpolars.github.io/) as alternatives to [`dplyr`]
  - To read and write CSV data, consider [`vroom`](https://vroom.r-lib.org/) instead of base R

## Code optimization: DRY on data frames

- Remember: DRY (Don't Repeat Yourself)
- Data frames are expensive, i.e. take a lot of time.
- Some examples:
  - Only create data frames, if really necessary. 
    - Bad: `if(nrow(filter(x, condition)) > 0)`
    - Good: `if(any(condition))`
  - Assemble a data frame only once, not iteratively.
  - When subsetting a data frame and working with a column, first extract the column and then subset.

## Code optimization: Don't copy

## Code optimization: Vectorize where possible

- Avoiding for loops does not help much anymore.
- However, using specialized vectorized functions (implemented in compiled code) helps:
  - Base R: `rowSums()`, `colSums()`, `rowMeans()`, `colMeans()`
  - [`matrixStats`](https://github.com/HenrikBengtsson/matrixStats): many! `anyMissing()`, `colQuantiles()`, `rowMax()`, etc.
  - [`collapse`](https://sebkrantz.github.io/collapse/): `fmean()`, `TRA()`, `GRP()`, ...

## Code optimization: Shift to C++ with `Rcpp`

## References
